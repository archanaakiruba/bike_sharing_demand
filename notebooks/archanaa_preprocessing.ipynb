{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv, json\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, Point\n",
    "import requests\n",
    "import holidays\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from bikesharing.params import *\n",
    "from bikesharing.ml_logic.data import *\n",
    "from bikesharing.ml_logic.encoders import *\n",
    "from bikesharing.ml_logic.feature_engineering import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre-processing functions ##\n",
    "\n",
    "def pre_process_rental_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocesses the rental DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The preprocessed DataFrame.\n",
    "    \"\"\"\n",
    "    # Select relevant columns only\n",
    "    df = df[['STARTTIME', 'STARTLAT', 'STARTLON']].copy()\n",
    "\n",
    "    # Strip column names\n",
    "    df.columns = [col.strip() for col in df.columns]\n",
    "\n",
    "    # Remove column 'Row'\n",
    "    df.drop(columns='Row', inplace=True, errors='ignore')\n",
    "\n",
    "    # Make string replacements\n",
    "    df_obj = df.select_dtypes(include='object')\n",
    "    df[df_obj.columns] = df_obj.applymap(lambda x: x.strip().replace(',', '.') if isinstance(x, str) else x)\n",
    "\n",
    "    # Handle datetime and numerical datatypes\n",
    "    df.STARTTIME = pd.to_datetime(df.STARTTIME)\n",
    "    df[['STARTLAT', 'STARTLON']] = df[['STARTLAT', 'STARTLON']].astype(np.float32)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_polygons(polygons_file: str) -> dict:\n",
    "    \"\"\"\n",
    "    Loads polygons from a file and returns them as a dictionary.\n",
    "\n",
    "    Args:\n",
    "        polygons_file (str): The path to the polygons file.\n",
    "\n",
    "    Returns:\n",
    "        dict: The dictionary of polygons.\n",
    "    \"\"\"\n",
    "    polygons = {}\n",
    "    with open(polygons_file, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            polygons[row['district']] = Polygon(json.loads(row['coordinates']))\n",
    "\n",
    "    return polygons\n",
    "\n",
    "\n",
    "def get_district_from_polygons(rental_df: pd.DataFrame, polygons: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Performs a spatial join between the rental DataFrame and polygons.\n",
    "\n",
    "    Args:\n",
    "        rental_df (pd.DataFrame): The rental DataFrame.\n",
    "        polygons (dict): The dictionary of polygons.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the spatial join result.\n",
    "    \"\"\"\n",
    "    # Create a DataFrame from the polygons dictionary\n",
    "    polygons_df = pd.DataFrame.from_dict(polygons, orient='index', columns=['geometry'])\n",
    "    # Reset the index to make the 'district' column a regular column\n",
    "    polygons_df = polygons_df.reset_index().rename(columns={'index': 'district'})\n",
    "\n",
    "    # Create a GeoDataFrame from the polygons DataFrame\n",
    "    polygons_gdf = gpd.GeoDataFrame(polygons_df)\n",
    "    # Set the geometry column in the polygons_gdf GeoDataFrame\n",
    "    polygons_gdf.set_geometry('geometry', inplace=True)\n",
    "\n",
    "    # Create a GeoDataFrame from the point data\n",
    "    geometry = [Point(row['STARTLON'], row['STARTLAT']) for _, row in rental_df.iterrows()]\n",
    "    rental_gdf = gpd.GeoDataFrame(rental_df, geometry=geometry)\n",
    "    # Set the geometry column in the rental_gdf GeoDataFrame\n",
    "    rental_gdf.set_geometry('geometry', inplace=True)\n",
    "\n",
    "    # Perform the spatial join\n",
    "    rental_geo_df = gpd.sjoin(rental_gdf, polygons_gdf, predicate='within')\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    rental_geo_df = rental_geo_df.drop(columns=['geometry', 'index_right', 'STARTLON', 'STARTLAT'])\n",
    "\n",
    "    return rental_geo_df\n",
    "\n",
    "\n",
    "def encode_district_label(rental_df: pd.DataFrame, polygons: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Encodes the district labels in the DataFrame using one-hot encoding.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with encoded district labels.\n",
    "    \"\"\"\n",
    "    df = get_district_from_polygons(rental_df, polygons)\n",
    "\n",
    "    # Instantiate the OneHotEncoder\n",
    "    district_ohe = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "    # Fit encoder\n",
    "    district_ohe.fit(df[['district']])\n",
    "\n",
    "    # Apply one-hot encoding and add the encoded columns to the DataFrame\n",
    "    encoded_columns = district_ohe.get_feature_names_out()\n",
    "    encoded_values = district_ohe.transform(df[['district']])\n",
    "    df[encoded_columns] = encoded_values\n",
    "    df.drop(columns=['district'] , inplace=True)\n",
    "\n",
    "    # Update the column names in df without the prefix 'district_'\n",
    "    column_names = [column.split('district_', 1)[-1] for column in df.columns]\n",
    "    df.columns = column_names\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def group_rental_data_by_hour(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Groups the rental data by hour and sums the values for each district.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with rental data grouped by hour and the sum of values for each district.\n",
    "    \"\"\"\n",
    "    # Convert STARTTIME column to datetime\n",
    "    df['STARTTIME'] = pd.to_datetime(df['STARTTIME'])\n",
    "\n",
    "    # Extract date and hour from STARTTIME column\n",
    "    df['rent_date_hour'] = df['STARTTIME'].dt.floor('H')\n",
    "\n",
    "    # Exclude datetime and rent_date_hour columns from summation\n",
    "    district_columns = [col for col in df.columns if col not in ['STARTTIME', 'rent_date_hour']]\n",
    "\n",
    "    # Grouping by Hour and summing the values for each district\n",
    "    df_by_hour = df.groupby('rent_date_hour')[district_columns].sum().reset_index()\n",
    "\n",
    "    return df_by_hour\n",
    "\n",
    "\n",
    "def get_weather_info(rental_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieves weather information and merges it with the rental data.\n",
    "\n",
    "    Args:\n",
    "        rental_df (pd.DataFrame): The rental DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with merged rental and weather data.\n",
    "    \"\"\"\n",
    "    def fetch_weather_data(latitude, longitude, start_date, end_date):\n",
    "        # TODO: should be moved to env\n",
    "        url = \"https://archive-api.open-meteo.com/v1/era5\"\n",
    "        params = {\n",
    "            'latitude': latitude,\n",
    "            'longitude': longitude,\n",
    "            'start_date': start_date,\n",
    "            'end_date': end_date,\n",
    "            'hourly': ['temperature_2m', 'relativehumidity_2m', 'apparent_temperature', 'windspeed_10m', 'precipitation']\n",
    "        }\n",
    "        weather_data = requests.get(url, params=params).json()\n",
    "        df_weather = pd.DataFrame(weather_data['hourly'])\n",
    "        df_weather['time'] = pd.to_datetime(df_weather['time'])\n",
    "\n",
    "        return df_weather\n",
    "\n",
    "    # Merge rental data with weather data\n",
    "    df_weather = fetch_weather_data()\n",
    "    merged_data = rental_df.merge(df_weather, left_on='date_hour', right_on='time', how='left').drop(columns='time')\n",
    "    merged_data['date_hour'] = pd.to_datetime(merged_data['date_hour'])\n",
    "\n",
    "    return merged_data\n",
    "\n",
    "\n",
    "def feature_extraction(data: pd.DataFrame) -> tuple:\n",
    "    \"\"\"\n",
    "    Performs feature engineering on the input data.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the features DataFrame (X) and the target DataFrame (y).\n",
    "    \"\"\"\n",
    "    data['date_hour'] = pd.to_datetime(data['date_hour'])\n",
    "\n",
    "    # Extract date from date_hour\n",
    "    data['date'] = data['date_hour'].dt.date\n",
    "\n",
    "    # Select features for X and y\n",
    "    X = data[['date', 'date_hour', 'year', 'month', 'hour', 'temperature_2m', 'relativehumidity_2m',\n",
    "              'apparent_temperature', 'windspeed_10m', 'precipitation']]\n",
    "    \n",
    "    X['date'] = pd.to_datetime(X['date'])\n",
    "    X['is_weekend'] = X['date'].dt.weekday >= 5\n",
    "\n",
    "    bay_holidays = holidays.CountryHoliday('DE', prov='BY')\n",
    "    X['is_holiday'] = X['date'].apply(lambda x: x in bay_holidays)\n",
    "    \n",
    "    y = data[['date_hour','Sendling-Westpark', 'Altstadt-Lehel', 'Schwabing-West', 'Untergiesing',\n",
    "       'Untergiesing-Harlaching', 'Maxvorstadt', 'Bogenhausen', 'Sendling',\n",
    "       'Milbertshofen-Am Hart', 'Neuhausen-Nymphenburg', 'Moosach',\n",
    "       'Obergiesing', 'Au - Haidhausen', 'Ludwigsvorstadt-Isarvorstadt',\n",
    "       'Laim', 'Schwanthalerh√∂he', 'Schwabing-Freimann', 'Ramersdorf-Perlach',\n",
    "       'Thalkirchen', 'Aubing-Lochhausen-Langwied', 'Hadern', 'Berg am Laim',\n",
    "       'Harlaching', 'Obersendling', 'S√ºdgiesing', 'Pasing',\n",
    "       'Pasing-Obermenzing', 'Hasenbergl-Lerchenau Ost', 'Obermenzing',\n",
    "       'Trudering', 'Trudering-Riem', 'Feldmoching', 'Untermenzing-Allach',\n",
    "       'Lochhausen']].copy()\n",
    "    \n",
    "    # Add sine and cosine transformations of time-related features\n",
    "    time_features = ['hour', 'month', 'date_hour.dt.weekday']\n",
    "    for feature in time_features:\n",
    "        X[f'{feature}_sin'] = np.sin(2 * np.pi * X[feature] / X[feature].max())\n",
    "        X[f'{feature}_cos'] = np.cos(2 * np.pi * X[feature] / X[feature].max())\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def scale_numeric_features(data: pd.DataFrame, numeric_features: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Scales the numeric features in the given DataFrame using StandardScaler.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The input DataFrame.\n",
    "        numeric_features (list): List of column names representing the numeric features to scale.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with scaled numeric features.\n",
    "    \"\"\"\n",
    "    scaled_data = data.copy()\n",
    "\n",
    "    # Scale the numeric features\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data[numeric_features] = scaler.fit_transform(scaled_data[numeric_features])\n",
    "\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Load data from local CSV...\u001b[0m\n",
      "‚úÖ Data loaded, with shape (2802995, 3)\n",
      "(2802995, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STARTTIME</th>\n",
       "      <th>STARTLAT</th>\n",
       "      <th>STARTLON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 02:47:00</td>\n",
       "      <td>48.088402</td>\n",
       "      <td>11.48060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "      <td>48.105709</td>\n",
       "      <td>11.41446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 15:29:00</td>\n",
       "      <td>48.155258</td>\n",
       "      <td>11.54012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             STARTTIME   STARTLAT  STARTLON\n",
       "0  2019-01-01 02:47:00  48.088402  11.48060\n",
       "1  2019-01-01 04:00:00  48.105709  11.41446\n",
       "2  2019-01-01 15:29:00  48.155258  11.54012"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the SQL query to fetch rental data from BigQuery\n",
    "query = f'''SELECT STARTTIME, STARTLAT, STARTLON\n",
    "         FROM `{GCP_PROJECT}.{BQ_DATASET}.raw_data_mvg`\n",
    "         WHERE STARTTIME >= '{START_YEAR}-01-01' AND STARTTIME <= '{END_YEAR}-12-31' \n",
    "         '''\n",
    "\n",
    "# Fetch the rental data from BigQuery\n",
    "cache_path = Path(LOCAL_DATA_PATH).joinpath(\"raw\", f\"raw_{START_YEAR}_{END_YEAR}.csv\")\n",
    "rentals_df = get_raw_data(GCP_PROJECT, query, cache_path)\n",
    "print(rentals_df.shape)\n",
    "rentals_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2802995, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STARTTIME</th>\n",
       "      <th>STARTLAT</th>\n",
       "      <th>STARTLON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 02:47:00</td>\n",
       "      <td>48.088402</td>\n",
       "      <td>11.48060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "      <td>48.105709</td>\n",
       "      <td>11.41446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 15:29:00</td>\n",
       "      <td>48.155258</td>\n",
       "      <td>11.54012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            STARTTIME   STARTLAT  STARTLON\n",
       "0 2019-01-01 02:47:00  48.088402  11.48060\n",
       "1 2019-01-01 04:00:00  48.105709  11.41446\n",
       "2 2019-01-01 15:29:00  48.155258  11.54012"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the rental data\n",
    "rental_df_processed = pre_process_rental_df(rentals_df)\n",
    "print(rental_df_processed.shape)\n",
    "# rental_df_processed.to_csv('../raw_data/preprocesses_rental_df.csv')\n",
    "rental_df_processed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Duplicate Rows: 23391\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Check\n",
    "duplicate_count = rental_df_processed.duplicated().sum()\n",
    "print(\"Number of Duplicate Rows:\", duplicate_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "# Load polygons from the file\n",
    "polygons_file_path = '../raw_data/polygons.csv'\n",
    "polygons = get_polygons(polygons_file_path)\n",
    "print(len(polygons))\n",
    "\n",
    "# Perform spatial join between rental data and polygons\n",
    "#rental_geo_df = get_district(rental_df_processed, polygons)\n",
    "#print(rental_geo_df.shape)\n",
    "# rental_geo_df.to_csv('../raw_data/rental_geo_df.csv')\n",
    "#rental_geo_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rental_geo_df = pd.read_csv('../raw_data/rental_geo_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2647946, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STARTTIME</th>\n",
       "      <th>Altstadt-Lehel</th>\n",
       "      <th>Au - Haidhausen</th>\n",
       "      <th>Aubing-Lochhausen-Langwied</th>\n",
       "      <th>Berg am Laim</th>\n",
       "      <th>Bogenhausen</th>\n",
       "      <th>Feldmoching</th>\n",
       "      <th>Hadern</th>\n",
       "      <th>Harlaching</th>\n",
       "      <th>Hasenbergl-Lerchenau Ost</th>\n",
       "      <th>...</th>\n",
       "      <th>Schwanthalerh√∂he</th>\n",
       "      <th>Sendling</th>\n",
       "      <th>Sendling-Westpark</th>\n",
       "      <th>S√ºdgiesing</th>\n",
       "      <th>Thalkirchen</th>\n",
       "      <th>Trudering</th>\n",
       "      <th>Trudering-Riem</th>\n",
       "      <th>Untergiesing</th>\n",
       "      <th>Untergiesing-Harlaching</th>\n",
       "      <th>Untermenzing-Allach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 15:29:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-05 12:19:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-06 08:31:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             STARTTIME  Altstadt-Lehel  Au - Haidhausen  \\\n",
       "0  2019-01-01 15:29:00             0.0              0.0   \n",
       "1  2019-01-05 12:19:00             0.0              0.0   \n",
       "2  2019-01-06 08:31:00             0.0              0.0   \n",
       "\n",
       "   Aubing-Lochhausen-Langwied  Berg am Laim  Bogenhausen  Feldmoching  Hadern  \\\n",
       "0                         0.0           0.0          0.0          0.0     0.0   \n",
       "1                         0.0           0.0          0.0          0.0     0.0   \n",
       "2                         0.0           0.0          0.0          0.0     0.0   \n",
       "\n",
       "   Harlaching  Hasenbergl-Lerchenau Ost  ...  Schwanthalerh√∂he  Sendling  \\\n",
       "0         0.0                       0.0  ...               0.0       0.0   \n",
       "1         0.0                       0.0  ...               0.0       0.0   \n",
       "2         0.0                       0.0  ...               0.0       0.0   \n",
       "\n",
       "   Sendling-Westpark  S√ºdgiesing  Thalkirchen  Trudering  Trudering-Riem  \\\n",
       "0                0.0         0.0          0.0        0.0             0.0   \n",
       "1                0.0         0.0          0.0        0.0             0.0   \n",
       "2                0.0         0.0          0.0        0.0             0.0   \n",
       "\n",
       "   Untergiesing  Untergiesing-Harlaching  Untermenzing-Allach  \n",
       "0           0.0                      0.0                  0.0  \n",
       "1           0.0                      0.0                  0.0  \n",
       "2           0.0                      0.0                  0.0  \n",
       "\n",
       "[3 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode district labels using one-hot encoding\n",
    "encoded_rental_df = encode_district_label(rental_df_processed, polygons)\n",
    "print(encoded_rental_df.shape)\n",
    "# encoded_rental_df.to_csv('../raw_data/encoded_rental_df.csv', index=False)\n",
    "encoded_rental_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_rental_df = pd.read_csv('../raw_data/encoded_rental_df.csv', index_col=False)\n",
    "# print(encoded_rental_df.shape)\n",
    "# encoded_rental_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34608, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rent_date_hour</th>\n",
       "      <th>Altstadt-Lehel</th>\n",
       "      <th>Au - Haidhausen</th>\n",
       "      <th>Aubing-Lochhausen-Langwied</th>\n",
       "      <th>Berg am Laim</th>\n",
       "      <th>Bogenhausen</th>\n",
       "      <th>Feldmoching</th>\n",
       "      <th>Hadern</th>\n",
       "      <th>Harlaching</th>\n",
       "      <th>Hasenbergl-Lerchenau Ost</th>\n",
       "      <th>...</th>\n",
       "      <th>Schwanthalerh√∂he</th>\n",
       "      <th>Sendling</th>\n",
       "      <th>Sendling-Westpark</th>\n",
       "      <th>S√ºdgiesing</th>\n",
       "      <th>Thalkirchen</th>\n",
       "      <th>Trudering</th>\n",
       "      <th>Trudering-Riem</th>\n",
       "      <th>Untergiesing</th>\n",
       "      <th>Untergiesing-Harlaching</th>\n",
       "      <th>Untermenzing-Allach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rent_date_hour  Altstadt-Lehel  Au - Haidhausen  \\\n",
       "0 2019-01-01 00:00:00             1.0              0.0   \n",
       "1 2019-01-01 01:00:00             0.0              0.0   \n",
       "2 2019-01-01 02:00:00             1.0              1.0   \n",
       "\n",
       "   Aubing-Lochhausen-Langwied  Berg am Laim  Bogenhausen  Feldmoching  Hadern  \\\n",
       "0                         0.0           0.0          0.0          0.0     0.0   \n",
       "1                         0.0           0.0          2.0          0.0     0.0   \n",
       "2                         0.0           0.0          2.0          0.0     0.0   \n",
       "\n",
       "   Harlaching  Hasenbergl-Lerchenau Ost  ...  Schwanthalerh√∂he  Sendling  \\\n",
       "0         0.0                       0.0  ...               0.0       0.0   \n",
       "1         0.0                       0.0  ...               0.0       2.0   \n",
       "2         0.0                       0.0  ...               0.0       5.0   \n",
       "\n",
       "   Sendling-Westpark  S√ºdgiesing  Thalkirchen  Trudering  Trudering-Riem  \\\n",
       "0                2.0         0.0          0.0        0.0             0.0   \n",
       "1                0.0         0.0          0.0        0.0             0.0   \n",
       "2                0.0         0.0          0.0        0.0             0.0   \n",
       "\n",
       "   Untergiesing  Untergiesing-Harlaching  Untermenzing-Allach  \n",
       "0           0.0                      0.0                  0.0  \n",
       "1           1.0                      1.0                  0.0  \n",
       "2           1.0                      1.0                  0.0  \n",
       "\n",
       "[3 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group rental data by hour\n",
    "rental_df_by_hour = group_rental_data_by_hour(encoded_rental_df)\n",
    "print(rental_df_by_hour.shape)\n",
    "# rental_df_by_hour.to_csv('../raw_data/rental_df_by_hour.csv', index=False)\n",
    "rental_df_by_hour.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Load data from local CSV...\u001b[0m\n",
      "‚úÖ Data loaded, with shape (35064, 6)\n",
      "(35064, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>relativehumidity_2m</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>windspeed_10m</th>\n",
       "      <th>precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01T00:00</td>\n",
       "      <td>3.3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01T01:00</td>\n",
       "      <td>3.4</td>\n",
       "      <td>99</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01T02:00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               time  temperature_2m  relativehumidity_2m  \\\n",
       "0  2019-01-01T00:00             3.3                  100   \n",
       "1  2019-01-01T01:00             3.4                   99   \n",
       "2  2019-01-01T02:00             3.5                  100   \n",
       "\n",
       "   apparent_temperature  windspeed_10m  precipitation  \n",
       "0                   0.5            9.0            0.2  \n",
       "1                   0.4            9.7            0.1  \n",
       "2                   0.2           12.0            0.2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve weather information and merge with rental data\n",
    "cache_path = Path(LOCAL_DATA_PATH).joinpath(\"weather\", f\"weather_{START_YEAR}_{END_YEAR}.csv\")\n",
    "weather_df = get_weather_data(cache_path)\n",
    "print(weather_df.shape)\n",
    "weather_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34608, 40)\n",
      "Index(['rent_date_hour', 'Altstadt-Lehel', 'Au - Haidhausen',\n",
      "       'Aubing-Lochhausen-Langwied', 'Berg am Laim', 'Bogenhausen',\n",
      "       'Feldmoching', 'Hadern', 'Harlaching', 'Hasenbergl-Lerchenau Ost',\n",
      "       'Laim', 'Lochhausen', 'Ludwigsvorstadt-Isarvorstadt', 'Maxvorstadt',\n",
      "       'Milbertshofen-Am Hart', 'Moosach', 'Neuhausen-Nymphenburg',\n",
      "       'Obergiesing', 'Obermenzing', 'Obersendling', 'Pasing',\n",
      "       'Pasing-Obermenzing', 'Ramersdorf-Perlach', 'Schwabing-Freimann',\n",
      "       'Schwabing-West', 'Schwanthalerh√∂he', 'Sendling', 'Sendling-Westpark',\n",
      "       'S√ºdgiesing', 'Thalkirchen', 'Trudering', 'Trudering-Riem',\n",
      "       'Untergiesing', 'Untergiesing-Harlaching', 'Untermenzing-Allach',\n",
      "       'temperature_2m', 'relativehumidity_2m', 'apparent_temperature',\n",
      "       'windspeed_10m', 'precipitation'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Convert 'time' column to datetime in the weather_df DataFrame\n",
    "weather_df['time'] = pd.to_datetime(weather_df['time'])\n",
    "\n",
    "# Merge the DataFrames on the converted columns\n",
    "merged_df = rental_df_by_hour.merge(weather_df, left_on='rent_date_hour', right_on='time', how='left').drop(columns='time')\n",
    "\n",
    "# Convert 'rent_date_hour' column to datetime\n",
    "merged_df['rent_date_hour'] = pd.to_datetime(merged_df['rent_date_hour'])\n",
    "\n",
    "print(merged_df.shape)\n",
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34608, 42)\n",
      "Index(['rent_date_hour', 'Altstadt-Lehel', 'Au - Haidhausen',\n",
      "       'Aubing-Lochhausen-Langwied', 'Berg am Laim', 'Bogenhausen',\n",
      "       'Feldmoching', 'Hadern', 'Harlaching', 'Hasenbergl-Lerchenau Ost',\n",
      "       'Laim', 'Lochhausen', 'Ludwigsvorstadt-Isarvorstadt', 'Maxvorstadt',\n",
      "       'Milbertshofen-Am Hart', 'Moosach', 'Neuhausen-Nymphenburg',\n",
      "       'Obergiesing', 'Obermenzing', 'Obersendling', 'Pasing',\n",
      "       'Pasing-Obermenzing', 'Ramersdorf-Perlach', 'Schwabing-Freimann',\n",
      "       'Schwabing-West', 'Schwanthalerh√∂he', 'Sendling', 'Sendling-Westpark',\n",
      "       'S√ºdgiesing', 'Thalkirchen', 'Trudering', 'Trudering-Riem',\n",
      "       'Untergiesing', 'Untergiesing-Harlaching', 'Untermenzing-Allach',\n",
      "       'temperature_2m', 'relativehumidity_2m', 'apparent_temperature',\n",
      "       'windspeed_10m', 'precipitation', 'is_holiday', 'is_weekend'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "holiday_feature_df = is_holiday(merged_df)\n",
    "merged_holiday_df = merged_df.merge(holiday_feature_df, on='rent_date_hour', how='left')\n",
    "\n",
    "weekend_feature_df = is_weekend(merged_holiday_df)\n",
    "merged_df_all = merged_holiday_df.merge(weekend_feature_df, on='rent_date_hour', how='left')\n",
    "\n",
    "print(merged_df_all.shape)\n",
    "print(merged_df_all.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34608, 48)\n",
      "Index(['rent_date_hour', 'Altstadt-Lehel', 'Au - Haidhausen',\n",
      "       'Aubing-Lochhausen-Langwied', 'Berg am Laim', 'Bogenhausen',\n",
      "       'Feldmoching', 'Hadern', 'Harlaching', 'Hasenbergl-Lerchenau Ost',\n",
      "       'Laim', 'Lochhausen', 'Ludwigsvorstadt-Isarvorstadt', 'Maxvorstadt',\n",
      "       'Milbertshofen-Am Hart', 'Moosach', 'Neuhausen-Nymphenburg',\n",
      "       'Obergiesing', 'Obermenzing', 'Obersendling', 'Pasing',\n",
      "       'Pasing-Obermenzing', 'Ramersdorf-Perlach', 'Schwabing-Freimann',\n",
      "       'Schwabing-West', 'Schwanthalerh√∂he', 'Sendling', 'Sendling-Westpark',\n",
      "       'S√ºdgiesing', 'Thalkirchen', 'Trudering', 'Trudering-Riem',\n",
      "       'Untergiesing', 'Untergiesing-Harlaching', 'Untermenzing-Allach',\n",
      "       'temperature_2m', 'relativehumidity_2m', 'apparent_temperature',\n",
      "       'windspeed_10m', 'precipitation', 'is_holiday', 'is_weekend',\n",
      "       'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'day_sin', 'day_cos'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "encoded_df = encode_temporal_features(merged_df_all['rent_date_hour'])\n",
    "final_df = merged_df_all.merge(encoded_df , on='rent_date_hour' , how='inner')\n",
    "print(final_df.shape)\n",
    "print(final_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
